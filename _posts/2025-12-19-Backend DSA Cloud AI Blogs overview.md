---
title: Building a Scalable Backend with DynamoDB Streams â€” My Journey Before the AWS User Group Pwani Talk
date: 2025-12-06
categories: [Cloud]
tags: [aws, dynamodb, lambda, cloud, serverless]
comments: true
---

When I agreed to give an online presentation to the **AWS User Group Pwani**, I knew I didnâ€™t want to show slides full of theory. I wanted something real â€” something I could **build, demo, and explain**.

So I decided to create a **small but scalable backend system** using:

- API Gateway  
- AWS Lambda  
- DynamoDB  
- DynamoDB Streams  

Everything worked perfectly during the live session (thank God ğŸ˜…).  
But the journey of building it before the talkâ€¦  
thatâ€™s where the real learning happened.

This blog is about that journey â€” **what I built, what surprised me, and the gems I picked up along the way**.

Letâ€™s dive in.

---

## ğŸŒ± Why This Project?

Before the presentation, I wanted to answer one question:

> **How can you build a backend that can scale to millions of users without managing servers?**

AWS has many ways to answer that question, but **DynamoDB Streams** stood out because:

- Theyâ€™re simple but powerful  
- Theyâ€™re event-driven  
- They allow your backend to react to data in real time  

If youâ€™ve ever wanted to track changes in your database â€” who registered, who updated their profile, who deleted their account â€” **Streams are the perfect tool**.

---

## ğŸ§  DynamoDB Streams â€” Explained Like Youâ€™re 10

Think of your DynamoDB table as a notebook.

Every time someone:

- adds a new line  
- edits a line  
- erases a line  

DynamoDB Streams captures that event like a **security camera**.

Then it whispers to your Lambda function:

- â€œHey, someone added a new user!â€  
- â€œHey, someone updated their email!â€  
- â€œHey, someone deleted an item!â€  

Your Lambda can react instantly.

Thatâ€™s the magic of **event-driven architecture**.

---

## ğŸ› ï¸ Step 1: Building the Backend API

I started with the essentials:

- âœ” API Gateway endpoint â†’ `/register`  
- âœ” Lambda function â†’ validates & stores user data  
- âœ” DynamoDB table â†’ `Users`  
- âœ” Duplicate checks â†’ no repeated emails or usernames  

When a user registers, the API saves:

```json
{
  "name": "Alice",
  "email": "alice@gmail.com",
  "username": "al"
}
```
and returns:
```
json
{
  "message": "User registered successfully"
}
```
Simple. Clean. Serverless.

ğŸ”„ Step 2: Turning on DynamoDB Streams
Next, I enabled Streams on the Users table with:

Stream type: NEW_AND_OLD_IMAGES

This means:

INSERT â†’ record the new item

MODIFY â†’ record both old and new images

DELETE â†’ record the old image

Then I connected the Stream to a new Lambda:

ğŸ“Œ LogUserChangesFunction

This Lambda would â€œlistenâ€ to any change on the table.

âš™ï¸ Step 3: Building the Stream Processor Lambda
Hereâ€™s the Lambda handler:

```
export const handler = async (event) => {
  console.log("=== DynamoDB Stream Event Received ===");

  for (const record of event.Records) {
    const type = record.eventName;

    try {
      if (type === "INSERT") {
        console.log("USER ADDED:", JSON.stringify(record.dynamodb.NewImage));
      } else if (type === "MODIFY") {
        console.log("USER UPDATED - OLD:", JSON.stringify(record.dynamodb.OldImage));
        console.log("USER UPDATED - NEW:", JSON.stringify(record.dynamodb.NewImage));
      } else if (type === "REMOVE") {
        console.log("USER DELETED:", JSON.stringify(record.dynamodb.OldImage));
      } else {
        console.log("UNKNOWN EVENT:", type, record);
      }
    } catch (err) {
      console.error("Error processing record:", err, record);
      throw err;
    }
  }

  return { statusCode: 200 };
};

```
This tiny function became my activity logger for the entire database.


ğŸ§ª Step 4: Testing â€” Where the Learning Really Happened
This is where the real story lives.

ğŸ“Œ Mistake 1: Expecting Streams to Show Old Data
I added a user before turning on Streams.

Later, when I checked the logsâ€¦ nothing.

âœ… Streams only capture events after they are enabled

âŒ They do not show historical changes

ğŸ“Œ Mistake 2: Updating an Item Is Not an Insert
When I updated Eveâ€™s username from toto â†’ kichwa, I got:

```
USER UPDATED - OLD: ...
USER UPDATED - NEW: ...
Exactly what I wanted.
```

ğŸ“Œ Mistake 3: IAM Is the Silent Gatekeeper
At first, I got errors like:

â€œCannot access stream. Ensure GetRecords, ListStreams permissionsâ€¦â€

Streams wonâ€™t even fire unless IAM is correct.

The Lambda needs:

```
dynamodb:GetRecords
dynamodb:GetShardIterator
dynamodb:DescribeStream
dynamodb:ListStreams
```

Once I fixed that, everything worked flawlessly.

ğŸ“ˆ Why This Architecture Is Actually Scalable
This simple system becomes extremely powerful because each part scales automatically:

1ï¸âƒ£ API Gateway
Handles thousands of requests per second.

2ï¸âƒ£ Lambda
Scales by spawning new instances based on traffic.

3ï¸âƒ£ DynamoDB
Scales horizontally and supports millions of reads/writes per second.

4ï¸âƒ£ DynamoDB Streams
Process events asynchronously without slowing down the main API.

No servers.
No patching.
No capacity planning.

---
Just pure scalability.

ğŸ§© What I Learned (The Real Takeaways)
âœ” Serverless is not about writing less code

âœ” Real scalability comes from loose coupling

âœ” IAM is everything

âœ” Logs are your best debugging tool

âœ” Event-driven architecture is addictive

---

ğŸ¤ Final Thoughts
When I finally gave the presentation to AWS User Group Pwani, everything worked smoothly â€” no errors, no surprises, just a clean demo.

But the real win was everything I learned before that moment.

I didnâ€™t just build an API.
I built a scalable, event-driven backend using real AWS production tools.

If you're curious about serverless, DynamoDB Streams is one of the best places to start.

Simple idea â†’ big power.

And who knows â€” your next small experiment might become your next talkâ€¦ or your next startup ğŸš€


